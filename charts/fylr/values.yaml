# Default values for fylr.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: docker.fylr.io/fylr/fylr-server
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: "v6.1.0-beta.8"

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podAnnotations: {}

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

services:
  webapp:
    type: ClusterIP
    port: 8080
  api:
    type: ClusterIP
    port: 8081
  backend:
    type: ClusterIP
    port: 8082

ingress:
  enabled: true
  className: "nginx"
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: localhost
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80

nodeSelector: {}

tolerations: []

affinity: {}

fylr:
  # public external url of the server. This url needs to be fully qualified
  externalURL: "http://localhost"
  # set to true to allow /api/settings/purge. should be disabled for production!
  allowPurge: true
  logger:
    # format is the format of the logs. Valid values are "json" and "console".
    format: "console"
    # level is the minimum level of logs to be logged. Valid values are "trace", "debug", "info", "warn", "error", "fatal", "panic".
    level: "info"
    # timeFormat is the Go representation to format the time in the log output.
    # zerolog's time keeping resolution is always set to milliseconds by FYLR.
    # Use "", "UNIXMS" or "UNIXMICRO" to output a unix timestamp (json format only).
    # Defaults to "2006-01-02 15:04:05"
    timeFormat: "2006-01-02 15:04:05"
    # noColor disables colorized output.
    noColor: false
    # addHostname adds the hostname to the logs.
    addHostname: true

  persistent:
    defaults:
      originals: "disk1"
      versions: "disk2"
      backups: "s3"
    definitions:
      s3:
        # kind is the kind of the storage. Valid values are "s3" and "disk".
        kind: s3
        # allow fylr to purge files from the disk.
        # This is a dangerous setting and should be used for development purposes only.
        allowPurge: false
        # s3 is the configuration for the s3 storage.
        s3:
          # path represents the path in the s3 bucket.
          path: ""
          # bucket is the name of the bucket to use.
          bucket: fylr
          # endpoint is the endpoint of the s3 server.
          endpoint: "http://localhost:9000"
          # accessKey is the access key to use.
          accessKey: "minio"
          # secretKey is the secret key to use.
          secretKey: "minio123"
          # region is the region of the s3 server.
          region: "us-east-1"
          # useSSL enables SSL for the s3 connection.
          useSSL: false
          # allowRedirect specifies whether we expose s3 urls to the outside world.
          allowRedirect: false
      disk1:
        # kind is the kind of the storage. Valid values are "s3" and "disk".
        kind: disk
        # allow fylr to purge files from the disk.
        # This is a dangerous setting and should be used for development purposes only.
        allowPurge: false
        # disk is the configuration for the disk storage (persistent volume).
        disk:
          # storageClass is the storage class of the file system. Check your kubernetes infrastructure for the available storage classes.
          storageClass: ""
          # accessModes is a list of access modes for the volume.
          # If the replica count is greater than 1, the access modes must contain "ReadWriteMany".
          # If the replica count is > 1 and the access modes are set to "ReadWriteOnce", the replica count will be set to 1.
          # This is required because the volume cannot be mounted by more than one pod at a time.
          # If we would allow this, the data would be spread across the pods and it will likely be impossible to receive the data back.
          accessModes: ["ReadWriteOnce"]
          # size is the size of the disk to be claimed and used by fylr.
          size: 10Gi
      disk2:
        # kind is the kind of the storage. Valid values are "s3" and "disk".
        kind: disk
        # allow fylr to purge files from the disk.
        # This is a dangerous setting and should be used for development purposes only.
        allowPurge: false
        # disk is the configuration for the disk storage (persistent volume).
        disk:
          # storageClass is the storage class of the file system. Check your kubernetes infrastructure for the available storage classes.
          storageClass: ""
          # accessModes is a list of access modes for the volume.
          # If the replica count is greater than 1, the access modes must contain "ReadWriteMany".
          # If the replica count is > 1 and the access modes are set to "ReadWriteOnce", the replica count will be set to 1.
          # This is required because the volume cannot be mounted by more than one pod at a time.
          # If we would allow this, the data would be spread across the pods and it will likely be impossible to receive the data back.
          accessModes: ["ReadWriteOnce"]
          # size is the size of the disk to be claimed and used by fylr.
          size: 10Gi

  db:
    # driver will be ignored if postgresql-ha is enabled
    driver: "postgres"
    # postgres will be ignored if postgresql-ha is enabled
    postgres:
      host: "localhost"
      port: 5432
      user: "fylr"
      password: "password"
      database: "fylr"
      sslmode: "disable"
      # options is a map of additional options to be passed to the database connection string.
      # See https://www.postgresql.org/docs/current/libpq-connect.html#LIBPQ-PARAMKEYWORDS
      options: {}
      #  sslcert: /fylr/files/certs/postgres-ca.crt
    # This has to be at 4 + execserver.parallel + elastic.parallel. Two of these
    # connections will be dedicated to a separate connection pool managing
    # the sequences (Postgres only)
    # https://golang.org/pkg/database/sql/#DB.SetMaxOpenConns, default: 0
    maxOpenConns: 12
    # maxIdleConns has to be not more than maxOpenConns
    # https://golang.org/pkg/database/sql/#DB.SetMaxIdleConns, default: 0
    maxIdleConns: 0
    # The init block is used to pre-fill the database when its created or purged.
    init:
      # Inline base config. Works like configFile but used the inlined
      # baseconfig setting in this .yml file. Runs after configFile, so everything
      # in config overwrites settings from configFile. Default is empty.
      config: {}

  plugin:
    # paths is a list of paths to search for plugins. Defaults to the plugins directories for easydb and fylr.
    paths:
      - /fylr/files/plugins/easydb
      - /fylr/files/plugins/fylr
    defaults:
      fylr_example:
        # enable, set to false to disable the plugin, defaults to true
        enabled: false
        # update_policy: automatic, always, never, defaults to automatic
        update: "never"
      # not compatible with fylr
      easydb-connector-plugin:
        enabled: false
        update: "never"
  elastic:
    # logger used for the elastic client
    # "Text": TextLogger prints the log message in plain text.
    # "Color": ColorLogger prints the log message in a terminal-optimized plain text.
    # "Curl": CurlLogger prints the log message as a runnable curl command.
    # "JSON": JSONLogger prints the log message as JSON.
    logger: ""
    # Where to find the Elastic search index settings. If you provide your own
    # file make sure to base it on the default
    # resources/index/index_settings.json which is included in the distribution.
    settings: ""
    # number of parallel workers to index documents, default to 1, set to 0 to disable
    parallel: 4
    # number of objects per job passed to the indexer process
    objectsPerJob: 100
    # limit of payloads sent to Elastic
    maxMem: 100mb
    # fielddata (debug feature). if set to true, fields are mapped including their fielddata
    # in the reverse index. with that, the inspect view of the indexed version of
    # the object shows a per field list of stored terms. This can be useful for debugging
    # of analyzer settings.
    fielddata: false
    # addresses of the elastic servers
    addresses:
      - "http://localhost:9200"
    # username
    username: ""
    # password
    password: ""
  execserver:
    # number of parallel file workers, default to 1, set to 0 to disable
    parallel: 4
    # pluginJobTimeoutSec sets the maximum seconds a callback
    # is allowed to run. Defaults to 30 seconds.
    pluginJobTimeoutSec: 240
    # connectTimeout sets the maximum seconds the server will wait
    # until a worker gets a job. Defaults to 60 seconds.
    connectTimeoutSec: 240
    # addresses represents a list of execserver services.
    # If execserver.enabled is set to true, this option will be ignored.
    # We expect the url in the format of "http://localhost:8080".
    addresses: []
  services:
    api:
      oauth2Server:
        # additional oauth2 clients to be added to the oauth2 server.
        # For the web application, we automatically generate a key pair and assign it to the oauth2 client.
        clients: {}
          # my-client-id:
          #   # secret must be given as bcrypt hash
          #   secret: $2y$04$81xGNnm8PS1uiIzjbos6Le3NzFaNB0goNqnBpOx7S/EyrayzJCNAq # foo
          #   # this must point to the public URL or the webapp (/oauth2/callback)
          #   redirectURIs:
          #     - http://localhost/oauth2/callback
          #   # the scopes this client needs to be granted
          #   # offline is mandatory to issue refresh tokens
          #   # others will be used in rights management
          #   scopes:
          #     - "read"
          #     - "write"
          #     - "offline"
          #   # public, set to true if this client is publicly known
          #   public: false
    webapp:
      # basicAuth is used to protect the web application with additional basic credentials.
      # We expect a map of usernames and passwords in clear text.
      basicAuth: {}
      #  myuser: mypassword
      #  myuser2: mypassword2
      #  ...

execserver:
  # TODO: add config for the execserver
  enabled: true

# third party services

# minio (s3 compatible storage)
# If enabled and no change has been made, fylr uses the internal kubernetes mino service
# fylr will use it for "assets", "versions" and "backups".
# Even if you decide to make it available to the outside world, we still use the Kubernetes service.
# This means that fylr does not expose the S3 URLs for "assets", "versions" and "backups".
# Instead, the URLs point to fylr itself.
#
# For more information about minio and how to use it, see: https://github.com/minio/minio/tree/master/helm/minio
minio:
  enabled: true
  replicas: 3
  projectName: minio
  image:
    repository: quay.io/minio/minio
    pullPolicy: IfNotPresent
    # Overrides the image tag whose default is the chart appVersion.
    tag: "RELEASE.2022-09-01T23-53-36Z"
  rootUser: minio
  rootPassword: minio123
  persistence:
    enabled: true
    storageClass: ""
    accessMode: ReadWriteOnce
    size: 50Gi
  resources:
    requests:
      memory: 1Gi
      cpu: 100m
  users:
    # the first user will be used as ouline user
    - accessKey: fylr
      secretKey: fylrsecret123
      policy: fylrbucketrw
  buckets:
    - name: fylr
      policy: none
      purge: false
      versioning: true
      objectlocking: false
  policies:
    - name: fylrbucketrw
      statements:
        - resources:
          - 'arn:aws:s3:::fylr/*'
          actions:
          - 's3:*'
          conditions:
            - StringEquals: '"aws:username": "fylr"'

# -- postgresql deployment
# for more information see: https://github.com/bitnami/charts/tree/master/bitnami/postgresql-ha
postgresql-ha:
  enabled: true
  pgpool:
    adminUsername: fylr
    adminPassword: fylr
    tls:
      enabled: true
      autoGenerated: true
  postgresql:
    image:
      registry: docker.io
      repository: bitnami/postgresql-repmgr
      tag: 14.5.0-debian-11-r13
    resources:
      requests:
        memory: 512Mi
        cpu: 250m
      limits:
        memory: 2Gi
        cpu: 2000m
    username: fylr
    password: fylr
    database: fylr
  persistence:
    enabled: true
    storageClass: ""
    accessModes:
    - ReadWriteOnce
    size: 10Gi

# -- elasticsearch deployment
# for more information see: https://github.com/bitnami/charts/blob/master/bitnami/elasticsearch/values.yaml
elasticsearch:
  enabled: true
  clusterName: fylr
  ## @param plugins Comma, semi-colon or space separated list of plugins to install at initialization
  ## ref: https://github.com/bitnami/containers/tree/main/bitnami/elasticsearch#environment-variables
  ##
  plugins: "analysis-icu"
  master:
    ## @param master.masterOnly Deploy the Elasticsearch master-elegible nodes as master-only nodes. Recommended for high-demand deployments.
    ## If you are
    masterOnly: true
    ## @param master.replicaCount Number of master-elegible replicas to deploy
    ##
    replicaCount: 3
    ## @param master.updateStrategy.type Master-elegible nodes statefulset stategy type
    ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
    ##
    updateStrategy:
      type: RollingUpdate
    ## Elasticsearch resource requests and limits
    ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
    ## @param master.resources.limits The resources limits for the master-elegible containers
    ## @param master.resources.requests [object] The requested resources for the master-elegible containers
    ##
    resources:
      limits: {}
      requests:
        cpu: 25m
        memory: 256Mi
    ## @param master.heapSize Elasticsearch master-eligible node heap size.
    ## Note: The recommended heapSize is half of the container's memory.
    ## If omitted, it will be automatically set.
    ## Example:
    ##   heapSize: 128m
    ##
    heapSize: 128m
    ## Configure Pods Security Context
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
    ## @param master.podSecurityContext.enabled Enabled master-elegible pods' Security Context
    ## @param master.podSecurityContext.fsGroup Set master-elegible pod's Security Context fsGroup
    ##
    podSecurityContext:
      enabled: true
      fsGroup: 1001
    ## Configure Container Security Context
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
    ## @param master.containerSecurityContext.enabled Enabled master-elegible containers' Security Context
    ## @param master.containerSecurityContext.runAsUser Set master-elegible containers' Security Context runAsUser
    ## @param master.containerSecurityContext.runAsNonRoot Set master-elegible containers' Security Context runAsNonRoot
    ##
    containerSecurityContext:
      enabled: true
      runAsUser: 1001
      runAsNonRoot: true
    ## Configure extra options for Elasticsearch master-elegible containers' liveness, readiness and startup probes
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
    ## @param master.startupProbe.enabled Enable/disable the startup probe (master nodes pod)
    ## @param master.startupProbe.initialDelaySeconds Delay before startup probe is initiated (master nodes pod)
    ## @param master.startupProbe.periodSeconds How often to perform the probe (master nodes pod)
    ## @param master.startupProbe.timeoutSeconds When the probe times out (master nodes pod)
    ## @param master.startupProbe.successThreshold Minimum consecutive successes for the probe to be considered successful after having failed (master nodes pod)
    ## @param master.startupProbe.failureThreshold Minimum consecutive failures for the probe to be considered failed after having succeeded
    ##
    startupProbe:
      enabled: false
      initialDelaySeconds: 90
      periodSeconds: 10
      timeoutSeconds: 5
      successThreshold: 1
      failureThreshold: 5
    ## @param master.livenessProbe.enabled Enable/disable the liveness probe (master-eligible nodes pod)
    ## @param master.livenessProbe.initialDelaySeconds Delay before liveness probe is initiated (master-eligible nodes pod)
    ## @param master.livenessProbe.periodSeconds How often to perform the probe (master-eligible nodes pod)
    ## @param master.livenessProbe.timeoutSeconds When the probe times out (master-eligible nodes pod)
    ## @param master.livenessProbe.successThreshold Minimum consecutive successes for the probe to be considered successful after having failed (master-eligible nodes pod)
    ## @param master.livenessProbe.failureThreshold Minimum consecutive failures for the probe to be considered failed after having succeeded
    ##
    livenessProbe:
      enabled: true
      initialDelaySeconds: 90
      periodSeconds: 10
      timeoutSeconds: 5
      successThreshold: 1
      failureThreshold: 5
    ## @param master.readinessProbe.enabled Enable/disable the readiness probe (master-eligible nodes pod)
    ## @param master.readinessProbe.initialDelaySeconds Delay before readiness probe is initiated (master-eligible nodes pod)
    ## @param master.readinessProbe.periodSeconds How often to perform the probe (master-eligible nodes pod)
    ## @param master.readinessProbe.timeoutSeconds When the probe times out (master-eligible nodes pod)
    ## @param master.readinessProbe.successThreshold Minimum consecutive successes for the probe to be considered successful after having failed (master-eligible nodes pod)
    ## @param master.readinessProbe.failureThreshold Minimum consecutive failures for the probe to be considered failed after having succeeded
    ##
    readinessProbe:
      enabled: true
      initialDelaySeconds: 90
      periodSeconds: 10
      timeoutSeconds: 5
      successThreshold: 1
      failureThreshold: 5
    ## Enable persistence using Persistent Volume Claims
    ## ref: https://kubernetes.io/docs/user-guide/persistent-volumes/
    ##
    persistence:
      ## @param master.persistence.enabled Enable persistence using a `PersistentVolumeClaim`
      ##
      enabled: true
      ## @param master.persistence.storageClass Persistent Volume Storage Class
      ## If defined, storageClassName: <storageClass>
      ## If set to "-", storageClassName: "", which disables dynamic provisioning
      ## If undefined (the default) or set to null, no storageClassName spec is
      ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
      ##   GKE, AWS & OpenStack)
      ##
      storageClass: ""
      ## @param master.persistence.existingClaim Existing Persistent Volume Claim
      ## then accept the value as an existing Persistent Volume Claim to which
      ## the container should be bound
      ##
      existingClaim: ""
      ## @param master.persistence.existingVolume Existing Persistent Volume for use as volume match label selector to the `volumeClaimTemplate`. Ignored when `master.persistence.selector` is set.
      ##
      existingVolume: ""
      ## @param master.persistence.selector Configure custom selector for existing Persistent Volume. Overwrites `master.persistence.existingVolume`
      ## selector:
      ##   matchLabels:
      ##     volume:
      ##
      selector: {}
      ## @param master.persistence.annotations Persistent Volume Claim annotations
      ##
      annotations: {}
      ## @param master.persistence.accessModes Persistent Volume Access Modes
      ##
      accessModes:
        - ReadWriteOnce
      ## @param master.persistence.size Persistent Volume Size
      ##
      size: 25Gi
    ## Enable HorizontalPodAutoscaler for Elasticsearch Master pods
    ## ref: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
    ## @param master.autoscaling.enabled Whether enable horizontal pod autoscale
    ## @param master.autoscaling.minReplicas Configure a minimum amount of pods
    ## @param master.autoscaling.maxReplicas Configure a maximum amount of pods
    ## @param master.autoscaling.targetCPU Define the CPU target to trigger the scaling actions (utilization percentage)
    ## @param master.autoscaling.targetMemory Define the memory target to trigger the scaling actions (utilization percentage)
    ##
    autoscaling:
      enabled: true
      minReplicas: 3
      maxReplicas: 11
      targetCPU: ""
      targetMemory: ""

  ## @section Data node parameters
  data:
    ## @param data.replicaCount Number of data-only replicas to deploy
    ##
    replicaCount: 3
    ## @param data.updateStrategy.type Data-only nodes statefulset stategy type
    ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
    ##
    updateStrategy:
      type: RollingUpdate
    ## Elasticsearch resource requests and limits
    ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
    ## @param data.resources.limits The resources limits for the data containers
    ## @param data.resources.requests [object] The requested resources for the data containers
    ##
    resources:
      limits: {}
      requests:
        cpu: 25m
        memory: 2048Mi
    ## @param data.heapSize Elasticsearch data node heap size.
    ## Note: The recommended heapSize is half of the container's memory.
    ## If omitted, it will be automatically set.
    ## Example:
    ##   heapSize: 128m
    ##
    heapSize: 1024m
    ## Configure Pods Security Context
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
    ## @param data.podSecurityContext.enabled Enabled data pods' Security Context
    ## @param data.podSecurityContext.fsGroup Set data pod's Security Context fsGroup
    ##
    podSecurityContext:
      enabled: true
      fsGroup: 1001
    ## Configure Container Security Context
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
    ## @param data.containerSecurityContext.enabled Enabled data containers' Security Context
    ## @param data.containerSecurityContext.runAsUser Set data containers' Security Context runAsUser
    ## @param data.containerSecurityContext.runAsNonRoot Set data containers' Security Context runAsNonRoot
    ##
    containerSecurityContext:
      enabled: true
      runAsUser: 1001
      runAsNonRoot: true
    ## @param data.affinity Affinity for data pods assignment
    ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
    ## NOTE: `data.podAffinityPreset`, `data.podAntiAffinityPreset`, and `data.nodeAffinityPreset` will be ignored when it's set
    ##
    affinity: {}
    ## @param data.nodeSelector Node labels for data pods assignment
    ## ref: https://kubernetes.io/docs/user-guide/node-selection/
    ##
    nodeSelector: {}
    ## @param data.tolerations Tolerations for data pods assignment
    ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
    ##
    tolerations: []
    ## @param data.priorityClassName data pods' priorityClassName
    ##
    priorityClassName: ""
    ## @param data.schedulerName Name of the k8s scheduler (other than default) for data pods
    ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
    ##
    schedulerName: ""
    podManagementPolicy: "Parallel"
    ## Configure extra options for Elasticsearch data containers' liveness, readiness and startup probes
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
    ## @param data.startupProbe.enabled Enable/disable the startup probe (data nodes pod)
    ## @param data.startupProbe.initialDelaySeconds Delay before startup probe is initiated (data nodes pod)
    ## @param data.startupProbe.periodSeconds How often to perform the probe (data nodes pod)
    ## @param data.startupProbe.timeoutSeconds When the probe times out (data nodes pod)
    ## @param data.startupProbe.successThreshold Minimum consecutive successes for the probe to be considered successful after having failed (data nodes pod)
    ## @param data.startupProbe.failureThreshold Minimum consecutive failures for the probe to be considered failed after having succeeded
    ##
    startupProbe:
      enabled: false
      initialDelaySeconds: 90
      periodSeconds: 10
      timeoutSeconds: 5
      successThreshold: 1
      failureThreshold: 5
    ## @param data.livenessProbe.enabled Enable/disable the liveness probe (data nodes pod)
    ## @param data.livenessProbe.initialDelaySeconds Delay before liveness probe is initiated (data nodes pod)
    ## @param data.livenessProbe.periodSeconds How often to perform the probe (data nodes pod)
    ## @param data.livenessProbe.timeoutSeconds When the probe times out (data nodes pod)
    ## @param data.livenessProbe.successThreshold Minimum consecutive successes for the probe to be considered successful after having failed (data nodes pod)
    ## @param data.livenessProbe.failureThreshold Minimum consecutive failures for the probe to be considered failed after having succeeded
    ##
    livenessProbe:
      enabled: true
      initialDelaySeconds: 90
      periodSeconds: 10
      timeoutSeconds: 5
      successThreshold: 1
      failureThreshold: 5
    ## @param data.readinessProbe.enabled Enable/disable the readiness probe (data nodes pod)
    ## @param data.readinessProbe.initialDelaySeconds Delay before readiness probe is initiated (data nodes pod)
    ## @param data.readinessProbe.periodSeconds How often to perform the probe (data nodes pod)
    ## @param data.readinessProbe.timeoutSeconds When the probe times out (data nodes pod)
    ## @param data.readinessProbe.successThreshold Minimum consecutive successes for the probe to be considered successful after having failed (data nodes pod)
    ## @param data.readinessProbe.failureThreshold Minimum consecutive failures for the probe to be considered failed after having succeeded
    ##
    readinessProbe:
      enabled: true
      initialDelaySeconds: 90
      periodSeconds: 10
      timeoutSeconds: 5
      successThreshold: 1
      failureThreshold: 5
    ## @param data.customStartupProbe Override default startup probe
    ##
    customStartupProbe: {}
    ## @param data.customLivenessProbe Override default liveness probe
    ##
    customLivenessProbe: {}
    ## @param data.customReadinessProbe Override default readiness probe
    ##
    customReadinessProbe: {}
    ## @param data.command Override default container command (useful when using custom images)
    ##
    command: []
    ## @param data.args Override default container args (useful when using custom images)
    ##
    args: []
    ## @param data.lifecycleHooks for the data container(s) to automate configuration before or after startup
    ##
    lifecycleHooks: {}
    ## @param data.extraEnvVars Array with extra environment variables to add to data nodes
    ## e.g:
    ## extraEnvVars:
    ##   - name: FOO
    ##     value: "bar"
    ##
    extraEnvVars: []
    ## @param data.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for data nodes
    ##
    extraEnvVarsCM: ""
    ## @param data.extraEnvVarsSecret Name of existing Secret containing extra env vars for data nodes
    ##
    extraEnvVarsSecret: ""
    ## @param data.extraVolumes Optionally specify extra list of additional volumes for the data pod(s)
    ##
    extraVolumes: []
    ## @param data.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the data container(s)
    ##
    extraVolumeMounts: []
    ## @param data.sidecars Add additional sidecar containers to the data pod(s)
    ## e.g:
    ## sidecars:
    ##   - name: your-image-name
    ##     image: your-image
    ##     imagePullPolicy: Always
    ##     ports:
    ##       - name: portname
    ##         containerPort: 1234
    ##
    sidecars: []
    ## @param data.initContainers Add additional init containers to the data pod(s)
    ## ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
    ## e.g:
    ## initContainers:
    ##  - name: your-image-name
    ##    image: your-image
    ##    imagePullPolicy: Always
    ##    command: ['sh', '-c', 'echo "hello world"']
    ##
    initContainers: []
    ## Enable persistence using Persistent Volume Claims
    ## ref: https://kubernetes.io/docs/user-guide/persistent-volumes/
    ##
    persistence:
      ## @param data.persistence.enabled Enable persistence using a `PersistentVolumeClaim`
      ##
      enabled: true
      ## @param data.persistence.storageClass Persistent Volume Storage Class
      ## If defined, storageClassName: <storageClass>
      ## If set to "-", storageClassName: "", which disables dynamic provisioning
      ## If undefined (the default) or set to null, no storageClassName spec is
      ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
      ##   GKE, AWS & OpenStack)
      ##
      storageClass: ""
      ## @param data.persistence.existingClaim Existing Persistent Volume Claim
      ## then accept the value as an existing Persistent Volume Claim to which
      ## the container should be bound
      ##
      existingClaim: ""
      ## @param data.persistence.existingVolume Existing Persistent Volume for use as volume match label selector to the `volumeClaimTemplate`. Ignored when `data.persistence.selector` is set.
      ##
      existingVolume: ""
      ## @param data.persistence.selector Configure custom selector for existing Persistent Volume. Overwrites `data.persistence.existingVolume`
      ## selector:
      ##   matchLabels:
      ##     volume:
      ##
      selector: {}
      ## @param data.persistence.annotations Persistent Volume Claim annotations
      ##
      annotations: {}
      ## @param data.persistence.accessModes Persistent Volume Access Modes
      ##
      accessModes:
        - ReadWriteOnce
      ## @param data.persistence.size Persistent Volume Size
      ##
      size: 8Gi
    ## Pods Service Account
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
    ## @param data.serviceAccount.create Specifies whether a ServiceAccount should be created
    ## @param data.serviceAccount.name Name of the service account to use. If not set and create is true, a name is generated using the fullname template.
    ## @param data.serviceAccount.automountServiceAccountToken Automount service account token for the server service account
    ## @param data.serviceAccount.annotations Annotations for service account. Evaluated as a template. Only used if `create` is `true`.
    ##
    serviceAccount:
      create: false
      name: ""
      automountServiceAccountToken: true
      annotations: {}
    ## Enable HorizontalPodAutoscaler for Elasticsearch data pods
    ## ref: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
    ## @param data.autoscaling.enabled Whether enable horizontal pod autoscale
    ## @param data.autoscaling.minReplicas Configure a minimum amount of pods
    ## @param data.autoscaling.maxReplicas Configure a maximum amount of pods
    ## @param data.autoscaling.targetCPU Define the CPU target to trigger the scaling actions (utilization percentage)
    ## @param data.autoscaling.targetMemory Define the memory target to trigger the scaling actions (utilization percentage)
    ##
    autoscaling:
      enabled: false
      minReplicas: 3
      maxReplicas: 11
      targetCPU: ""
      targetMemory: ""

  ## @section Coordinating-only nodes parameters

  coordinating:
    ## @param coordinating.replicaCount Number of coordinating-only replicas to deploy
    ##
    replicaCount: 2
    ## @param coordinating.nameOverride String to partially override elasticsearch.coordinating.fullname
    ##
    nameOverride: ""
    ## @param coordinating.fullnameOverride String to fully override elasticsearch.coordinating.fullname
    ##
    fullnameOverride: ""
    ## @param coordinating.servicenameOverride String to fully override elasticsearch.coordinating.servicename
    ##
    servicenameOverride: ""
    ## @param coordinating.annotations [object] Annotations for the coordinating-only statefulset
    ##
    annotations: {}
    ## @param coordinating.updateStrategy.type Coordinating-only nodes statefulset stategy type
    ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
    ##
    updateStrategy:
      type: RollingUpdate
    ## Elasticsearch resource requests and limits
    ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
    ## @param coordinating.resources.limits The resources limits for the coordinating-only containers
    ## @param coordinating.resources.requests [object] The requested resources for the coordinating-only containers
    ##
    resources:
      limits: {}
      requests:
        cpu: 25m
        memory: 256Mi
    ## @param coordinating.heapSize Elasticsearch coordinating node heap size.
    ## Note: The recommended heapSize is half of the container's memory.
    ## If omitted, it will be automatically set.
    ## Example:
    ##   heapSize: 128m
    ##
    heapSize: 128m
    ## Configure Pods Security Context
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
    ## @param coordinating.podSecurityContext.enabled Enabled coordinating-only pods' Security Context
    ## @param coordinating.podSecurityContext.fsGroup Set coordinating-only pod's Security Context fsGroup
    ##
    podSecurityContext:
      enabled: true
      fsGroup: 1001
    ## Configure Container Security Context
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
    ## @param coordinating.containerSecurityContext.enabled Enabled coordinating-only containers' Security Context
    ## @param coordinating.containerSecurityContext.runAsUser Set coordinating-only containers' Security Context runAsUser
    ## @param coordinating.containerSecurityContext.runAsNonRoot Set coordinating-only containers' Security Context runAsNonRoot
    ##
    containerSecurityContext:
      enabled: true
      runAsUser: 1001
      runAsNonRoot: true
    ## @param coordinating.hostAliases coordinating-only pods host aliases
    ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
    ##
    hostAliases: []
    ## @param coordinating.podLabels Extra labels for coordinating-only pods
    ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
    ##
    podLabels: {}
    ## @param coordinating.podAnnotations Annotations for coordinating-only pods
    ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
    ##
    podAnnotations: {}
    ## @param coordinating.podAffinityPreset Pod affinity preset. Ignored if `coordinating.affinity` is set. Allowed values: `soft` or `hard`
    ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
    ##
    podAffinityPreset: ""
    ## @param coordinating.podAntiAffinityPreset Pod anti-affinity preset. Ignored if `coordinating.affinity` is set. Allowed values: `soft` or `hard`
    ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
    ##
    podAntiAffinityPreset: ""
    ## Node coordinating.affinity preset
    ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
    ##
    nodeAffinityPreset:
      ## @param coordinating.nodeAffinityPreset.type Node affinity preset type. Ignored if `coordinating.affinity` is set. Allowed values: `soft` or `hard`
      ##
      type: ""
      ## @param coordinating.nodeAffinityPreset.key Node label key to match. Ignored if `coordinating.affinity` is set
      ##
      key: ""
      ## @param coordinating.nodeAffinityPreset.values Node label values to match. Ignored if `coordinating.affinity` is set
      ## E.g.
      ## values:
      ##   - e2e-az1
      ##   - e2e-az2
      ##
      values: []
    ## @param coordinating.affinity Affinity for coordinating-only pods assignment
    ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
    ## NOTE: `coordinating.podAffinityPreset`, `coordinating.podAntiAffinityPreset`, and `coordinating.nodeAffinityPreset` will be ignored when it's set
    ##
    affinity: {}
    ## @param coordinating.nodeSelector Node labels for coordinating-only pods assignment
    ## ref: https://kubernetes.io/docs/user-guide/node-selection/
    ##
    nodeSelector: {}
    ## @param coordinating.tolerations Tolerations for coordinating-only pods assignment
    ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
    ##
    tolerations: []
    ## @param coordinating.priorityClassName coordinating-only pods' priorityClassName
    ##
    priorityClassName: ""
    ## @param coordinating.schedulerName Name of the k8s scheduler (other than default) for coordinating-only pods
    ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
    ##
    schedulerName: ""
    ## @param coordinating.terminationGracePeriodSeconds In seconds, time the given to the Elasticsearch coordinating pod needs to terminate gracefully
    ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods
    ##
    terminationGracePeriodSeconds: ""
    ## @param coordinating.topologySpreadConstraints Topology Spread Constraints for pod assignment spread across your cluster among failure-domains. Evaluated as a template
    ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods
    ##
    topologySpreadConstraints: []
    ## @param coordinating.podManagementPolicy podManagementPolicy to manage scaling operation of Elasticsearch coordinating pods
    ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
    ##
    podManagementPolicy: "Parallel"
    ## Configure extra options for Elasticsearch coordinating-only containers' liveness, readiness and startup probes
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
    ## @param coordinating.startupProbe.enabled Enable/disable the startup probe (coordinating-only nodes pod)
    ## @param coordinating.startupProbe.initialDelaySeconds Delay before startup probe is initiated (coordinating-only nodes pod)
    ## @param coordinating.startupProbe.periodSeconds How often to perform the probe (coordinating-only nodes pod)
    ## @param coordinating.startupProbe.timeoutSeconds When the probe times out (coordinating-only nodes pod)
    ## @param coordinating.startupProbe.successThreshold Minimum consecutive successes for the probe to be considered successful after having failed (coordinating-only nodes pod)
    ## @param coordinating.startupProbe.failureThreshold Minimum consecutive failures for the probe to be considered failed after having succeeded
    ##
    startupProbe:
      enabled: false
      initialDelaySeconds: 90
      periodSeconds: 10
      timeoutSeconds: 5
      successThreshold: 1
      failureThreshold: 5
    ## @param coordinating.livenessProbe.enabled Enable/disable the liveness probe (coordinating-only nodes pod)
    ## @param coordinating.livenessProbe.initialDelaySeconds Delay before liveness probe is initiated (coordinating-only nodes pod)
    ## @param coordinating.livenessProbe.periodSeconds How often to perform the probe (coordinating-only nodes pod)
    ## @param coordinating.livenessProbe.timeoutSeconds When the probe times out (coordinating-only nodes pod)
    ## @param coordinating.livenessProbe.successThreshold Minimum consecutive successes for the probe to be considered successful after having failed (coordinating-only nodes pod)
    ## @param coordinating.livenessProbe.failureThreshold Minimum consecutive failures for the probe to be considered failed after having succeeded
    ##
    livenessProbe:
      enabled: true
      initialDelaySeconds: 90
      periodSeconds: 10
      timeoutSeconds: 5
      successThreshold: 1
      failureThreshold: 5
    ## @param coordinating.readinessProbe.enabled Enable/disable the readiness probe (coordinating-only nodes pod)
    ## @param coordinating.readinessProbe.initialDelaySeconds Delay before readiness probe is initiated (coordinating-only nodes pod)
    ## @param coordinating.readinessProbe.periodSeconds How often to perform the probe (coordinating-only nodes pod)
    ## @param coordinating.readinessProbe.timeoutSeconds When the probe times out (coordinating-only nodes pod)
    ## @param coordinating.readinessProbe.successThreshold Minimum consecutive successes for the probe to be considered successful after having failed (coordinating-only nodes pod)
    ## @param coordinating.readinessProbe.failureThreshold Minimum consecutive failures for the probe to be considered failed after having succeeded
    ##
    readinessProbe:
      enabled: true
      initialDelaySeconds: 90
      periodSeconds: 10
      timeoutSeconds: 5
      successThreshold: 1
      failureThreshold: 5
    ## @param coordinating.customStartupProbe Override default startup probe
    ##
    customStartupProbe: {}
    ## @param coordinating.customLivenessProbe Override default liveness probe
    ##
    customLivenessProbe: {}
    ## @param coordinating.customReadinessProbe Override default readiness probe
    ##
    customReadinessProbe: {}
    ## @param coordinating.command Override default container command (useful when using custom images)
    ##
    command: []
    ## @param coordinating.args Override default container args (useful when using custom images)
    ##
    args: []
    ## @param coordinating.lifecycleHooks for the coordinating-only container(s) to automate configuration before or after startup
    ##
    lifecycleHooks: {}
    ## @param coordinating.extraEnvVars Array with extra environment variables to add to coordinating-only nodes
    ## e.g:
    ## extraEnvVars:
    ##   - name: FOO
    ##     value: "bar"
    ##
    extraEnvVars: []
    ## @param coordinating.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for coordinating-only nodes
    ##
    extraEnvVarsCM: ""
    ## @param coordinating.extraEnvVarsSecret Name of existing Secret containing extra env vars for coordinating-only nodes
    ##
    extraEnvVarsSecret: ""
    ## @param coordinating.extraVolumes Optionally specify extra list of additional volumes for the coordinating-only pod(s)
    ##
    extraVolumes: []
    ## @param coordinating.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the coordinating-only container(s)
    ##
    extraVolumeMounts: []
    ## @param coordinating.sidecars Add additional sidecar containers to the coordinating-only pod(s)
    ## e.g:
    ## sidecars:
    ##   - name: your-image-name
    ##     image: your-image
    ##     imagePullPolicy: Always
    ##     ports:
    ##       - name: portname
    ##         containerPort: 1234
    ##
    sidecars: []
    ## @param coordinating.initContainers Add additional init containers to the coordinating-only pod(s)
    ## ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
    ## e.g:
    ## initContainers:
    ##  - name: your-image-name
    ##    image: your-image
    ##    imagePullPolicy: Always
    ##    command: ['sh', '-c', 'echo "hello world"']
    ##
    initContainers: []
    ## Pods Service Account
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
    ## @param coordinating.serviceAccount.create Specifies whether a ServiceAccount should be created
    ## @param coordinating.serviceAccount.name Name of the service account to use. If not set and create is true, a name is generated using the fullname template.
    ## @param coordinating.serviceAccount.automountServiceAccountToken Automount service account token for the server service account
    ## @param coordinating.serviceAccount.annotations Annotations for service account. Evaluated as a template. Only used if `create` is `true`.
    ##
    serviceAccount:
      create: false
      name: ""
      automountServiceAccountToken: true
      annotations: {}
    ## Enable HorizontalPodAutoscaler for Elasticsearch coordinating pods
    ## ref: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
    ## @param coordinating.autoscaling.enabled Whether enable horizontal pod autoscale
    ## @param coordinating.autoscaling.minReplicas Configure a minimum amount of pods
    ## @param coordinating.autoscaling.maxReplicas Configure a maximum amount of pods
    ## @param coordinating.autoscaling.targetCPU Define the CPU target to trigger the scaling actions (utilization percentage)
    ## @param coordinating.autoscaling.targetMemory Define the memory target to trigger the scaling actions (utilization percentage)
    ##
    autoscaling:
      enabled: false
      minReplicas: 3
      maxReplicas: 11
      targetCPU: ""
      targetMemory: ""

  ## @section Ingest-only nodes parameters

  ingest:
    ## @param ingest.enabled Enable ingest nodes
    ##
    enabled: true
    ## @param ingest.replicaCount Number of ingest-only replicas to deploy
    ##
    replicaCount: 2
    ## @param ingest.nameOverride String to partially override elasticsearch.ingest.fullname
    ##
    nameOverride: ""
    ## @param ingest.fullnameOverride String to fully override elasticsearch.ingest.fullname
    ##
    fullnameOverride: ""
    ## @param ingest.servicenameOverride String to fully override ingest.master.servicename
    ##
    servicenameOverride: ""
    ## @param ingest.annotations [object] Annotations for the ingest statefulset
    ##
    annotations: {}
    ## @param ingest.containerPorts.restAPI Elasticsearch REST API port
    ## @param ingest.containerPorts.transport Elasticsearch Transport port
    ##
    containerPorts:
      restAPI: 9200
      transport: 9300
    ## @param ingest.updateStrategy.type Ingest-only nodes statefulset stategy type
    ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
    ##
    updateStrategy:
      type: RollingUpdate
    ## Elasticsearch resource requests and limits
    ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
    ## @param ingest.resources.limits The resources limits for the ingest-only containers
    ## @param ingest.resources.requests [object] The requested resources for the ingest-only containers
    ##
    resources:
      limits: {}
      requests:
        cpu: 25m
        memory: 256Mi
    ## @param ingest.heapSize Elasticsearch ingest-only node heap size.
    ## Note: The recommended heapSize is half of the container's memory.
    ## If omitted, it will be automatically set.
    ## Example:
    ##   heapSize: 128m
    ##
    heapSize: 128m
    ## Configure Pods Security Context
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
    ## @param ingest.podSecurityContext.enabled Enabled ingest-only pods' Security Context
    ## @param ingest.podSecurityContext.fsGroup Set ingest-only pod's Security Context fsGroup
    ##
    podSecurityContext:
      enabled: true
      fsGroup: 1001
    ## Configure Container Security Context
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
    ## @param ingest.containerSecurityContext.enabled Enabled ingest-only containers' Security Context
    ## @param ingest.containerSecurityContext.runAsUser Set ingest-only containers' Security Context runAsUser
    ## @param ingest.containerSecurityContext.runAsNonRoot Set ingest-only containers' Security Context runAsNonRoot
    ##
    containerSecurityContext:
      enabled: true
      runAsUser: 1001
      runAsNonRoot: true
    ## @param ingest.hostAliases ingest-only pods host aliases
    ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
    ##
    hostAliases: []
    ## @param ingest.podLabels Extra labels for ingest-only pods
    ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
    ##
    podLabels: {}
    ## @param ingest.podAnnotations Annotations for ingest-only pods
    ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
    ##
    podAnnotations: {}
    ## @param ingest.podAffinityPreset Pod affinity preset. Ignored if `ingest.affinity` is set. Allowed values: `soft` or `hard`
    ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
    ##
    podAffinityPreset: ""
    ## @param ingest.podAntiAffinityPreset Pod anti-affinity preset. Ignored if `ingest.affinity` is set. Allowed values: `soft` or `hard`
    ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
    ##
    podAntiAffinityPreset: ""
    ## Node ingest.affinity preset
    ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
    ##
    nodeAffinityPreset:
      ## @param ingest.nodeAffinityPreset.type Node affinity preset type. Ignored if `ingest.affinity` is set. Allowed values: `soft` or `hard`
      ##
      type: ""
      ## @param ingest.nodeAffinityPreset.key Node label key to match. Ignored if `ingest.affinity` is set
      ##
      key: ""
      ## @param ingest.nodeAffinityPreset.values Node label values to match. Ignored if `ingest.affinity` is set
      ## E.g.
      ## values:
      ##   - e2e-az1
      ##   - e2e-az2
      ##
      values: []
    ## @param ingest.affinity Affinity for ingest-only pods assignment
    ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
    ## NOTE: `ingest.podAffinityPreset`, `ingest.podAntiAffinityPreset`, and `ingest.nodeAffinityPreset` will be ignored when it's set
    ##
    affinity: {}
    ## @param ingest.nodeSelector Node labels for ingest-only pods assignment
    ## ref: https://kubernetes.io/docs/user-guide/node-selection/
    ##
    nodeSelector: {}
    ## @param ingest.tolerations Tolerations for ingest-only pods assignment
    ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
    ##
    tolerations: []
    ## @param ingest.priorityClassName ingest-only pods' priorityClassName
    ##
    priorityClassName: ""
    ## @param ingest.schedulerName Name of the k8s scheduler (other than default) for ingest-only pods
    ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
    ##
    schedulerName: ""
    ## @param ingest.terminationGracePeriodSeconds In seconds, time the given to the Elasticsearch ingest pod needs to terminate gracefully
    ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods
    ##
    terminationGracePeriodSeconds: ""
    ## @param ingest.topologySpreadConstraints Topology Spread Constraints for pod assignment spread across your cluster among failure-domains. Evaluated as a template
    ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods
    ##
    topologySpreadConstraints: []
    ## @param ingest.podManagementPolicy podManagementPolicy to manage scaling operation of Elasticsearch ingest pods
    ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
    ##
    podManagementPolicy: "Parallel"
    ## Configure extra options for Elasticsearch ingest-only containers' liveness, readiness and startup probes
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
    ## @param ingest.startupProbe.enabled Enable/disable the startup probe (ingest-only nodes pod)
    ## @param ingest.startupProbe.initialDelaySeconds Delay before startup probe is initiated (ingest-only nodes pod)
    ## @param ingest.startupProbe.periodSeconds How often to perform the probe (ingest-only nodes pod)
    ## @param ingest.startupProbe.timeoutSeconds When the probe times out (ingest-only nodes pod)
    ## @param ingest.startupProbe.successThreshold Minimum consecutive successes for the probe to be considered successful after having failed (ingest-only nodes pod)
    ## @param ingest.startupProbe.failureThreshold Minimum consecutive failures for the probe to be considered failed after having succeeded
    ##
    startupProbe:
      enabled: false
      initialDelaySeconds: 90
      periodSeconds: 10
      timeoutSeconds: 5
      successThreshold: 1
      failureThreshold: 5
    ## @param ingest.livenessProbe.enabled Enable/disable the liveness probe (ingest-only nodes pod)
    ## @param ingest.livenessProbe.initialDelaySeconds Delay before liveness probe is initiated (ingest-only nodes pod)
    ## @param ingest.livenessProbe.periodSeconds How often to perform the probe (ingest-only nodes pod)
    ## @param ingest.livenessProbe.timeoutSeconds When the probe times out (ingest-only nodes pod)
    ## @param ingest.livenessProbe.successThreshold Minimum consecutive successes for the probe to be considered successful after having failed (ingest-only nodes pod)
    ## @param ingest.livenessProbe.failureThreshold Minimum consecutive failures for the probe to be considered failed after having succeeded
    ##
    livenessProbe:
      enabled: true
      initialDelaySeconds: 90
      periodSeconds: 10
      timeoutSeconds: 5
      successThreshold: 1
      failureThreshold: 5
    ## @param ingest.readinessProbe.enabled Enable/disable the readiness probe (ingest-only nodes pod)
    ## @param ingest.readinessProbe.initialDelaySeconds Delay before readiness probe is initiated (ingest-only nodes pod)
    ## @param ingest.readinessProbe.periodSeconds How often to perform the probe (ingest-only nodes pod)
    ## @param ingest.readinessProbe.timeoutSeconds When the probe times out (ingest-only nodes pod)
    ## @param ingest.readinessProbe.successThreshold Minimum consecutive successes for the probe to be considered successful after having failed (ingest-only nodes pod)
    ## @param ingest.readinessProbe.failureThreshold Minimum consecutive failures for the probe to be considered failed after having succeeded
    ##
    readinessProbe:
      enabled: true
      initialDelaySeconds: 90
      periodSeconds: 10
      timeoutSeconds: 5
      successThreshold: 1
      failureThreshold: 5
    ## @param ingest.customStartupProbe Override default startup probe
    ##
    customStartupProbe: {}
    ## @param ingest.customLivenessProbe Override default liveness probe
    ##
    customLivenessProbe: {}
    ## @param ingest.customReadinessProbe Override default readiness probe
    ##
    customReadinessProbe: {}
    ## @param ingest.command Override default container command (useful when using custom images)
    ##
    command: []
    ## @param ingest.args Override default container args (useful when using custom images)
    ##
    args: []
    ## @param ingest.lifecycleHooks for the ingest-only container(s) to automate configuration before or after startup
    ##
    lifecycleHooks: {}
    ## @param ingest.extraEnvVars Array with extra environment variables to add to ingest-only nodes
    ## e.g:
    ## extraEnvVars:
    ##   - name: FOO
    ##     value: "bar"
    ##
    extraEnvVars: []
    ## @param ingest.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for ingest-only nodes
    ##
    extraEnvVarsCM: ""
    ## @param ingest.extraEnvVarsSecret Name of existing Secret containing extra env vars for ingest-only nodes
    ##
    extraEnvVarsSecret: ""
    ## @param ingest.extraVolumes Optionally specify extra list of additional volumes for the ingest-only pod(s)
    ##
    extraVolumes: []
    ## @param ingest.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the ingest-only container(s)
    ##
    extraVolumeMounts: []
    ## @param ingest.sidecars Add additional sidecar containers to the ingest-only pod(s)
    ## e.g:
    ## sidecars:
    ##   - name: your-image-name
    ##     image: your-image
    ##     imagePullPolicy: Always
    ##     ports:
    ##       - name: portname
    ##         containerPort: 1234
    ##
    sidecars: []
    ## @param ingest.initContainers Add additional init containers to the ingest-only pod(s)
    ## ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
    ## e.g:
    ## initContainers:
    ##  - name: your-image-name
    ##    image: your-image
    ##    imagePullPolicy: Always
    ##    command: ['sh', '-c', 'echo "hello world"']
    ##
    initContainers: []
    ## Pods Service Account
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
    ## @param ingest.serviceAccount.create Specifies whether a ServiceAccount should be created
    ## @param ingest.serviceAccount.name Name of the service account to use. If not set and create is true, a name is generated using the fullname template.
    ## @param ingest.serviceAccount.automountServiceAccountToken Automount service account token for the server service account
    ## @param ingest.serviceAccount.annotations Annotations for service account. Evaluated as a template. Only used if `create` is `true`.
    ##
    serviceAccount:
      create: false
      name: ""
      automountServiceAccountToken: true
      annotations: {}
    ## Enable HorizontalPodAutoscaler for Elasticsearch ingest-only pods
    ## ref: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
    ## @param ingest.autoscaling.enabled Whether enable horizontal pod autoscale
    ## @param ingest.autoscaling.minReplicas Configure a minimum amount of pods
    ## @param ingest.autoscaling.maxReplicas Configure a maximum amount of pods
    ## @param ingest.autoscaling.targetCPU Define the CPU target to trigger the scaling actions (utilization percentage)
    ## @param ingest.autoscaling.targetMemory Define the memory target to trigger the scaling actions (utilization percentage)
    ##
    autoscaling:
      enabled: false
      minReplicas: 3
      maxReplicas: 11
      targetCPU: ""
      targetMemory: ""

    ## Elasticsearch Ingest-only Service
    ## Recommended for heavy ingestion, improves performance by sending ingest traffic directly into the ingest nodes.
    ## NOTE: Ingest nodes will only accept index requests with an associated pipeline, any other request won't be rerouted.
    ##
    service:
      ## @param ingest.service.enabled Enable Ingest-only service
      ##
      enabled: false
      ## @param ingest.service.type Elasticsearch ingest-only service type
      ##
      type: ClusterIP
      ## @param ingest.service.ports.restAPI Elasticsearch service REST API port
      ## @param ingest.service.ports.transport Elasticsearch service transport port
      ##
      ports:
        restAPI: 9200
        transport: 9300
      ## Node ports to expose
      ## @param ingest.service.nodePorts.restAPI Node port for REST API
      ## @param ingest.service.nodePorts.transport Node port for REST API
      ## NOTE: choose port between <30000-32767>
      ##
      nodePorts:
        restAPI: ""
        transport: ""
      ## @param ingest.service.clusterIP Elasticsearch ingest-only service Cluster IP
      ## e.g.:
      ## clusterIP: None
      ##
      clusterIP: ""
      ## @param ingest.service.loadBalancerIP Elasticsearch ingest-only service Load Balancer IP
      ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-loadbalancer
      ##
      loadBalancerIP: ""
      ## @param ingest.service.loadBalancerSourceRanges Elasticsearch ingest-only service Load Balancer sources
      ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
      ## e.g:
      ## loadBalancerSourceRanges:
      ##   - 10.10.10.0/24
      ##
      loadBalancerSourceRanges: []
      ## @param ingest.service.externalTrafficPolicy Elasticsearch ingest-only service external traffic policy
      ## ref http://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
      ##
      externalTrafficPolicy: Cluster
      ## @param ingest.service.extraPorts Extra ports to expose (normally used with the `sidecar` value)
      ##
      extraPorts: []
      ## @param ingest.service.annotations Additional custom annotations for Elasticsearch ingest-only service
      ##
      annotations: {}
      ## @param ingest.service.sessionAffinity Session Affinity for Kubernetes service, can be "None" or "ClientIP"
      ## If "ClientIP", consecutive client requests will be directed to the same Pod
      ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies
      ##
      sessionAffinity: None
      ## @param ingest.service.sessionAffinityConfig Additional settings for the sessionAffinity
      ## sessionAffinityConfig:
      ##   clientIP:
      ##     timeoutSeconds: 300
      ##
      sessionAffinityConfig: {}
    ## Elasticsearch Ingest-only ingress parameters
    ## ref: http://kubernetes.io/docs/user-guide/ingress/
    ##
    ingress:
      ## @param ingest.ingress.enabled Enable ingress record generation for Elasticsearch
      ##
      enabled: false
      ## @param ingest.ingress.pathType Ingress path type
      ##
      pathType: ImplementationSpecific
      ## @param ingest.ingress.apiVersion Force Ingress API version (automatically detected if not set)
      ##
      apiVersion: ""
      ## @param ingest.ingress.hostname Default host for the ingress record
      ##
      hostname: elasticsearch-ingest.local
      ## @param ingest.ingress.path Default path for the ingress record
      ## NOTE: You may need to set this to '/*' in order to use this with ALB ingress controllers
      ##
      path: /
      ## @param ingest.ingress.annotations Additional annotations for the Ingress resource. To enable certificate autogeneration, place here your cert-manager annotations.
      ## Use this parameter to set the required annotations for cert-manager, see
      ## ref: https://cert-manager.io/docs/usage/ingress/#supported-annotations
      ## e.g:
      ## annotations:
      ##   kubernetes.io/ingress.class: nginx
      ##   cert-manager.io/cluster-issuer: cluster-issuer-name
      ##
      annotations: {}
      ## @param ingest.ingress.tls Enable TLS configuration for the host defined at `ingress.hostname` parameter
      ## TLS certificates will be retrieved from a TLS secret with name: `{{- printf "%s-tls" .Values.ingress.hostname }}`
      ## You can:
      ##   - Use the `ingress.secrets` parameter to create this TLS secret
      ##   - Rely on cert-manager to create it by setting the corresponding annotations
      ##   - Rely on Helm to create self-signed certificates by setting `ingress.selfSigned=true`
      ##
      tls: false
      ## @param ingest.ingress.selfSigned Create a TLS secret for this ingress record using self-signed certificates generated by Helm
      ##
      selfSigned: false
      ## @param ingest.ingress.ingressClassName IngressClass that will be be used to implement the Ingress (Kubernetes 1.18+)
      ## This is supported in Kubernetes 1.18+ and required if you have more than one IngressClass marked as the default for your cluster .
      ## ref: https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/
      ##
      ingressClassName: ""
      ## @param ingest.ingress.extraHosts An array with additional hostname(s) to be covered with the ingress record
      ## e.g:
      ## extraHosts:
      ##   - name: elasticsearch.local
      ##     path: /
      ##
      extraHosts: []
      ## @param ingest.ingress.extraPaths An array with additional arbitrary paths that may need to be added to the ingress under the main host
      ## e.g:
      ## extraPaths:
      ## - path: /*
      ##   backend:
      ##     serviceName: ssl-redirect
      ##     servicePort: use-annotation
      ##
      extraPaths: []
      ## @param ingest.ingress.extraTls TLS configuration for additional hostname(s) to be covered with this ingress record
      ## ref: https://kubernetes.io/docs/concepts/services-networking/ingress/#tls
      ## e.g:
      ## extraTls:
      ## - hosts:
      ##     - elasticsearch.local
      ##   secretName: elasticsearch.local-tls
      ##
      extraTls: []
      ## @param ingest.ingress.secrets Custom TLS certificates as secrets
      ## NOTE: 'key' and 'certificate' are expected in PEM format
      ## NOTE: 'name' should line up with a 'secretName' set further up
      ## If it is not set and you're using cert-manager, this is unneeded, as it will create a secret for you with valid certificates
      ## If it is not set and you're NOT using cert-manager either, self-signed certificates will be created valid for 365 days
      ## It is also possible to create and manage the certificates outside of this helm chart
      ## Please see README.md for more information
      ## e.g:
      ## secrets:
      ##   - name: elasticsearch.local-tls
      ##     key: |-
      ##       -----BEGIN RSA PRIVATE KEY-----
      ##       ...
      ##       -----END RSA PRIVATE KEY-----
      ##     certificate: |-
      ##       -----BEGIN CERTIFICATE-----
      ##       ...
      ##       -----END CERTIFICATE-----
      ##
      secrets: []
      ## @param ingest.ingress.extraRules Additional rules to be covered with this ingress record
      ## ref: https://kubernetes.io/docs/concepts/services-networking/ingress/#ingress-rules
      ## e.g:
      ## extraRules:
      ## - host: example.local
      ##     http:
      ##       path: /
      ##       backend:
      ##         service:
      ##           name: example-svc
      ##           port:
      ##             name: http
      ##
      extraRules: []


  ## @section Metrics parameters

  ## Elasticsearch Prometheus exporter configuration
  ## ref: https://hub.docker.com/r/bitnami/elasticsearch-exporter/tags/
  ##
  metrics:
    ## @param metrics.enabled Enable prometheus exporter
    ##
    enabled: false
    ## @param metrics.nameOverride Metrics pod name
    ##
    nameOverride: ""
    ## @param metrics.fullnameOverride String to fully override common.names.fullname
    ##
    fullnameOverride: ""
    ## @param metrics.image.registry Metrics exporter image registry
    ## @param metrics.image.repository Metrics exporter image repository
    ## @param metrics.image.tag Metrics exporter image tag
    ## @param metrics.image.digest Metrics exporter image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag
    ## @param metrics.image.pullPolicy Metrics exporter image pull policy
    ## @param metrics.image.pullSecrets Metrics exporter image pull secrets
    ##
    image:
      registry: docker.io
      repository: bitnami/elasticsearch-exporter
      tag: 1.5.0-debian-11-r21
      digest: ""
      pullPolicy: IfNotPresent
      ## Optionally specify an array of imagePullSecrets.
      ## Secrets must be manually created in the namespace.
      ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
      ## e.g:
      ## pullSecrets:
      ##   - myRegistryKeySecretName
      ##
      pullSecrets: []
    ## @param metrics.extraArgs Extra arguments to add to the default exporter command
    ## ref: https://github.com/justwatchcom/elasticsearch_exporter
    ## e.g
    ## extraArgs:
    ##   - --es.snapshots
    ##   - --es.indices
    ##
    extraArgs: []
    ## @param metrics.hostAliases Add deployment host aliases
    ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
    ##
    hostAliases: []
    ## @param metrics.schedulerName Name of the k8s scheduler (other than default)
    ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
    ##
    schedulerName: ""
    ## @param metrics.priorityClassName Elasticsearch metrics exporter pods' priorityClassName
    ##
    priorityClassName: ""
    ## Elasticsearch Prometheus exporter service type
    ##
    service:
      ## @param metrics.service.type Metrics exporter endpoint service type
      ##
      type: ClusterIP
      ## @param metrics.service.port Metrics exporter endpoint service port
      ##
      port: 9114
      ## @param metrics.service.annotations [object] Provide any additional annotations which may be required.
      ## This can be used to set the LoadBalancer service type to internal only.
      ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#internal-load-balancer
      ##
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9114"
    ## @param metrics.podAffinityPreset Metrics Pod affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
    ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
    ##
    podAffinityPreset: ""
    ## @param metrics.podAntiAffinityPreset Metrics Pod anti-affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
    ## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
    ##
    podAntiAffinityPreset: ""
    ## Node affinity preset
    ## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
    ## @param metrics.nodeAffinityPreset.type Metrics Node affinity preset type. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
    ## @param metrics.nodeAffinityPreset.key Metrics Node label key to match Ignored if `affinity` is set.
    ## @param metrics.nodeAffinityPreset.values Metrics Node label values to match. Ignored if `affinity` is set.
    ##
    nodeAffinityPreset:
      type: ""
      ## E.g.
      ## key: "kubernetes.io/e2e-az-name"
      ##
      key: ""
      ## E.g.
      ## values:
      ##   - e2e-az1
      ##   - e2e-az2
      ##
      values: []
    ## @param metrics.affinity Metrics Affinity for pod assignment
    ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
    ## Note: podAffinityPreset, podAntiAffinityPreset, and  nodeAffinityPreset will be ignored when it's set
    ##
    affinity: {}
    ## @param metrics.nodeSelector Metrics Node labels for pod assignment
    ## Ref: https://kubernetes.io/docs/user-guide/node-selection/
    ##
    nodeSelector: {}
    ## @param metrics.tolerations Metrics Tolerations for pod assignment
    ## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
    ##
    tolerations: []
    ## @param metrics.topologySpreadConstraints Topology Spread Constraints for pod assignment spread across your cluster among failure-domains. Evaluated as a template
    ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods
    ##
    topologySpreadConstraints: []
    ## Elasticsearch Prometheus exporter resource requests and limits
    ## ref: https://kubernetes.io/docs/user-guide/compute-resources/
    ## We usually recommend not to specify default resources and to leave this as a conscious
    ## choice for the user. This also increases chances charts run on environments with little
    ## resources, such as Minikube. If you do want to specify resources, uncomment the following
    ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    ## @param metrics.resources.limits The resources limits for the container
    ## @param metrics.resources.requests The requested resources for the container
    ##
    resources:
      ## Example:
      ## limits:
      ##    cpu: 100m
      ##    memory: 128Mi
      limits: {}
      ## Examples:
      ## requests:
      ##    cpu: 100m
      ##    memory: 128Mi
      requests: {}
    ## Elasticsearch metrics container's liveness probe
    ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes
    ## @param metrics.livenessProbe.enabled Enable/disable the liveness probe (metrics pod)
    ## @param metrics.livenessProbe.initialDelaySeconds Delay before liveness probe is initiated (metrics pod)
    ## @param metrics.livenessProbe.periodSeconds How often to perform the probe (metrics pod)
    ## @param metrics.livenessProbe.timeoutSeconds When the probe times out (metrics pod)
    ## @param metrics.livenessProbe.failureThreshold Minimum consecutive failures for the probe to be considered failed after having succeeded
    ## @param metrics.livenessProbe.successThreshold Minimum consecutive successes for the probe to be considered successful after having failed (metrics pod)
    ##
    livenessProbe:
      enabled: true
      initialDelaySeconds: 60
      periodSeconds: 10
      timeoutSeconds: 5
      successThreshold: 1
      failureThreshold: 5
    ## Elasticsearch metrics container's readiness probe
    ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes
    ## @param metrics.readinessProbe.enabled Enable/disable the readiness probe (metrics pod)
    ## @param metrics.readinessProbe.initialDelaySeconds Delay before readiness probe is initiated (metrics pod)
    ## @param metrics.readinessProbe.periodSeconds How often to perform the probe (metrics pod)
    ## @param metrics.readinessProbe.timeoutSeconds When the probe times out (metrics pod)
    ## @param metrics.readinessProbe.failureThreshold Minimum consecutive failures for the probe to be considered failed after having succeeded
    ## @param metrics.readinessProbe.successThreshold Minimum consecutive successes for the probe to be considered successful after having failed (metrics pod)
    ##
    readinessProbe:
      enabled: true
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 1
      successThreshold: 1
      failureThreshold: 5
    ## Elasticsearch metrics container's startup probe
    ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes
    ## @param metrics.startupProbe.enabled Enable/disable the startup probe (metrics pod)
    ## @param metrics.startupProbe.initialDelaySeconds Delay before startup probe is initiated (metrics pod)
    ## @param metrics.startupProbe.periodSeconds How often to perform the probe (metrics pod)
    ## @param metrics.startupProbe.timeoutSeconds When the probe times out (metrics pod)
    ## @param metrics.startupProbe.failureThreshold Minimum consecutive failures for the probe to be considered failed after having succeeded
    ## @param metrics.startupProbe.successThreshold Minimum consecutive successes for the probe to be considered successful after having failed (metrics pod)
    ##
    startupProbe:
      enabled: false
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 1
      successThreshold: 1
      failureThreshold: 5
    ## @param metrics.customStartupProbe Custom liveness probe for the Web component
    ##
    customStartupProbe: {}
    ## @param metrics.customLivenessProbe Custom liveness probe for the Web component
    ##
    customLivenessProbe: {}
    ## @param metrics.customReadinessProbe Custom readiness probe for the Web component
    ##
    customReadinessProbe: {}
    ## @param metrics.podAnnotations [object] Metrics exporter pod Annotation and Labels
    ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
    ##
    podAnnotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "9114"
    ## @param metrics.podLabels Extra labels to add to Pod
    ##
    podLabels: {}
    ## Configure Pods Security Context
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
    ## @param metrics.podSecurityContext.enabled Enabled Elasticsearch metrics exporter pods' Security Context
    ## @param metrics.podSecurityContext.fsGroup Set Elasticsearch metrics exporter pod's Security Context fsGroup
    ##
    podSecurityContext:
      enabled: true
      fsGroup: 1001
    ## Configure Container Security Context
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
    ## @param metrics.containerSecurityContext.enabled Enabled Elasticsearch metrics exporter containers' Security Context
    ## @param metrics.containerSecurityContext.runAsUser Set Elasticsearch metrics exporter containers' Security Context runAsUser
    ## @param metrics.containerSecurityContext.runAsNonRoot Set Elasticsearch metrics exporter container's Security Context runAsNonRoot
    ##
    containerSecurityContext:
      enabled: true
      runAsUser: 1001
      runAsNonRoot: true
    ## @param metrics.command Override default container command (useful when using custom images)
    ##
    command: []
    ## @param metrics.args Override default container args (useful when using custom images)
    ##
    args: []
    ## @param metrics.extraEnvVars Array with extra environment variables to add to Elasticsearch metrics exporter nodes
    ## e.g:
    ## extraEnvVars:
    ##   - name: FOO
    ##     value: "bar"
    ##
    extraEnvVars: []
    ## @param metrics.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for Elasticsearch metrics exporter nodes
    ##
    extraEnvVarsCM: ""
    ## @param metrics.extraEnvVarsSecret Name of existing Secret containing extra env vars for Elasticsearch metrics exporter nodes
    ##
    extraEnvVarsSecret: ""
    ## @param metrics.extraVolumes Optionally specify extra list of additional volumes for the Elasticsearch metrics exporter pod(s)
    ##
    extraVolumes: []
    ## @param metrics.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the Elasticsearch metrics exporter container(s)
    ##
    extraVolumeMounts: []
    ## @param metrics.sidecars Add additional sidecar containers to the Elasticsearch metrics exporter pod(s)
    ## e.g:
    ## sidecars:
    ##   - name: your-image-name
    ##     image: your-image
    ##     imagePullPolicy: Always
    ##     ports:
    ##       - name: portname
    ##         containerPort: 1234
    ##
    sidecars: []
    ## @param metrics.initContainers Add additional init containers to the Elasticsearch metrics exporter pod(s)
    ## ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
    ## e.g:
    ## initContainers:
    ##  - name: your-image-name
    ##    image: your-image
    ##    imagePullPolicy: Always
    ##    command: ['sh', '-c', 'echo "hello world"']
    ##
    initContainers: []
    ## Prometheus Operator ServiceMonitor configuration
    ##
    serviceMonitor:
      ## @param metrics.serviceMonitor.enabled Create ServiceMonitor Resource for scraping metrics using PrometheusOperator
      ##
      enabled: false
      ## @param metrics.serviceMonitor.namespace Namespace which Prometheus is running in
      ## e.g:
      ## namespace: monitoring
      ##
      namespace: ""
      ## @param metrics.serviceMonitor.jobLabel The name of the label on the target service to use as the job name in prometheus.
      ##
      jobLabel: ""
      ## @param metrics.serviceMonitor.interval Interval at which metrics should be scraped
      ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint
      ##
      interval: ""
      ## @param metrics.serviceMonitor.scrapeTimeout Timeout after which the scrape is ended
      ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint
      ##
      scrapeTimeout: ""
      ## @param metrics.serviceMonitor.relabelings RelabelConfigs to apply to samples before scraping
      ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#relabelconfig
      ##
      relabelings: []
      ## @param metrics.serviceMonitor.metricRelabelings MetricRelabelConfigs to apply to samples before ingestion
      ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#relabelconfig
      ##
      metricRelabelings: []
      ## @param metrics.serviceMonitor.selector ServiceMonitor selector labels
      ## ref: https://github.com/bitnami/charts/tree/master/bitnami/prometheus-operator#prometheus-configuration
      ##
      ## selector:
      ##   prometheus: my-prometheus
      ##
      selector: {}
      ## @param metrics.serviceMonitor.labels Extra labels for the ServiceMonitor
      ##
      labels: {}
      ## @param metrics.serviceMonitor.honorLabels honorLabels chooses the metric's labels on collisions with target labels
      ##
      honorLabels: false
    ## Prometheus Operator PrometheusRule configuration
    ##
    prometheusRule:
      ## @param metrics.prometheusRule.enabled Creates a Prometheus Operator PrometheusRule (also requires `metrics.enabled` to be `true` and `metrics.prometheusRule.rules`)
      ##
      enabled: false
      ## @param metrics.prometheusRule.namespace Namespace for the PrometheusRule Resource (defaults to the Release Namespace)
      ##
      namespace: ""
      ## @param metrics.prometheusRule.additionalLabels Additional labels that can be used so PrometheusRule will be discovered by Prometheus
      ##
      additionalLabels: {}
      ## @param metrics.prometheusRule.rules Prometheus Rule definitions
        # - alert: es cluster error
        #   annotations:
        #     summary: "es cluster error"
        #     description: "es cluster error, cluster state {{`{{`}} $labels.color {{`}}`}}"
        #   expr: elasticsearch_cluster_health_status{color="red"} ==1 or elasticsearch_cluster_health_status{color="yellow"} ==1
        #   for: 1m
        #   labels:
        #     severity: critical
        #     group: PaaS
      ##
      rules: []
